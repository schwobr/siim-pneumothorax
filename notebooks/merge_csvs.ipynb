{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import gc\n",
    "import cv2\n",
    "import PIL\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import pydicom\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pdb\n",
    "from dataclasses import dataclass\n",
    "from functools import partial\n",
    "\n",
    "from skimage.morphology import label\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.nn.functional import binary_cross_entropy_with_logits\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import WeightedRandomSampler, Sampler\n",
    "\n",
    "from fastai.vision.data import SegmentationItemList, SegmentationLabelList, ImageList, imagenet_stats\n",
    "from fastai.data_block import FloatList, FloatItem\n",
    "from fastai.basic_data import DatasetType\n",
    "from fastai.basic_train import Learner\n",
    "from fastai.callback import OptimWrapper\n",
    "from fastai.vision.image import Image, ImageSegment, image2np, pil2tensor\n",
    "from fastai.vision.transform import get_transforms\n",
    "from fastai.vision.learner import unet_learner, cnn_learner\n",
    "import fastai.vision.models as mod\n",
    "from fastai.callbacks import SaveModelCallback, LearnerCallback\n",
    "from fastai.metrics import accuracy\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# IMAGE SIZES\n",
    "TRAIN_SIZE = 256\n",
    "MAX_SIZE = 1388\n",
    "TEST_SIZE = 224\n",
    "TEST_OVERLAP = 64\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "# PATHS\n",
    "PROJECT_PATH = Path(\n",
    "    '/work/stages/schwob/siim-pneumothorax')\n",
    "FULL_TRAIN_PATH = PROJECT_PATH/'data/dicom-images-train'\n",
    "FULL_TEST_PATH = PROJECT_PATH/'data/dicom-images-test'\n",
    "DATA = PROJECT_PATH/'data'\n",
    "TRAIN_PATH = PROJECT_PATH/'data/train'\n",
    "TEST_PATH = PROJECT_PATH/'data/test'\n",
    "MODELS_PATH = PROJECT_PATH/'models/'\n",
    "SUB_PATH = PROJECT_PATH/'submissions/'\n",
    "LABELS_OLD = PROJECT_PATH/'data/train-rle.csv'\n",
    "LABELS = PROJECT_PATH/'data/train-rle-fastai2.csv'\n",
    "LABELS_POS = PROJECT_PATH/'data/train-rle-fastai_pos.csv'\n",
    "LABELS_CLASSIF = PROJECT_PATH/'data/train-rle-fastai-classif.csv'\n",
    "LOG = Path('/work/stages/schwob/runs')\n",
    "\n",
    "# LEARNER CONFIG\n",
    "BATCH_SIZE = 16\n",
    "WD = 0.1\n",
    "LR = 2e-4\n",
    "GROUP_LIMITS = None\n",
    "FREEZE_UNTIL = None\n",
    "EPOCHS = 10\n",
    "UNFROZE_EPOCHS = 10\n",
    "PRETRAINED = True\n",
    "MODEL = 'resnet34'\n",
    "CLASSES = ['pneum']\n",
    "ACT = 'sigmoid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absol2relat(rle):\n",
    "    if str(rle) == '-1': return '-1'\n",
    "    pixels = rle.split()\n",
    "    new_rle = []\n",
    "    cur = 0\n",
    "    for k in range(0, len(pixels), 2):\n",
    "        if k==0:\n",
    "            new_rle.append(pixels[k])\n",
    "            new_rle.append(pixels[k+1])\n",
    "        else:\n",
    "            cur = int(pixels[k])\n",
    "            prev = int(pixels[k-2])+int(pixels[k-1])\n",
    "            new_rle.append(str(cur-prev))\n",
    "            new_rle.append(pixels[k+1])\n",
    "    return ' '.join(new_rle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relat2absol(rle):\n",
    "    if str(rle) == '-1': return '-1'\n",
    "    pixels = rle.split()\n",
    "    new_rle = []\n",
    "    cur = 0\n",
    "    for k in range(0, len(pixels), 2):\n",
    "        pix = pixels[k]\n",
    "        cur += int(pix)\n",
    "        length = pixels[k+1]\n",
    "        new_rle.append(str(cur))\n",
    "        new_rle.append(length)\n",
    "        cur += int(length)\n",
    "    return ' '.join(new_rle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_rles(rle1, rle2):\n",
    "    if rle1 == rle2: return rle1\n",
    "    i1 = 0\n",
    "    i2 = 0\n",
    "    rle = []\n",
    "    pixels1 = relat2absol(rle1).split()\n",
    "    pixels2 = relat2absol(rle2).split()\n",
    "    while i1<len(pixels1) and i2<len(pixels2):\n",
    "        p1 = int(pixels1[i1])\n",
    "        l1 = int(pixels1[i1+1])\n",
    "        p2 = int(pixels2[i2])\n",
    "        l2 = int(pixels2[i2+1])\n",
    "        if p1<=p2: \n",
    "            rle.append(str(p1))\n",
    "            if p2<=p1+l1-1:\n",
    "                rle.append(str(max(p2-p1+l2, l1)))\n",
    "                i2 += 2\n",
    "            else:\n",
    "                rle.append(str(l1))\n",
    "            i1 += 2\n",
    "        else: \n",
    "            rle.append(str(p2))\n",
    "            if p1<=p2+l2-1:\n",
    "                rle.append(str(max(p1-p2+l1, l2)))\n",
    "                i1 += 2\n",
    "            else:\n",
    "                rle.append(str(l2))\n",
    "            i2 += 2\n",
    "            \n",
    "    rle += pixels1[i1:]+pixels2[i2:]\n",
    "    return absol2relat(' '.join(rle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_doubles(old, new):\n",
    "    df = pd.read_csv(old)\n",
    "    new_df = pd.DataFrame(columns=['ImageId', 'EncodedPixels'])\n",
    "    for k, id in enumerate(df['ImageId'].unique()):\n",
    "        new_rle = ''\n",
    "        for rle in df.loc[df['ImageId']==id, 'EncodedPixels']:\n",
    "            new_rle = merge_rles(new_rle, rle)\n",
    "        new_df.loc[k] = [id, new_rle]\n",
    "    new_df.to_csv(new, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fn in SUB_PATH.iterdir():\n",
    "    if fn.suffix == '.csv':\n",
    "        merge_doubles(fn, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
